<!-- Banner -->
<p align="center">
  <img src="assets/Cover Photo.jpg" alt="Profile banner" width="1200" />
</p>

<h1 align="center">Nithin Melala Eshwarappa (李杰克)</h1>

<p align="center">
  <b>Ph.D. Candidate</b> · CSIE, National Chung Cheng University (CCU), Taiwan<br/>
  Distributed AI Systems · Cloud–Edge–Fog Computing · Orchestration · MARL · Federated Learning
</p>

<p align="center">
  <a href="<your-lab-or-website-link>"><b>Lab</b></a> ·
  <a href="<your-google-scholar-link>"><b>Google Scholar</b></a> ·
  <a href="<your-linkedin-link>"><b>LinkedIn</b></a> ·
  <a href="mailto:<your-email>"><b>Email</b></a>
</p>

---

## About
I am a Ph.D. candidate in **Computer Science and Information Engineering** at **National Chung Cheng University (CCU), Taiwan**. My research focuses on **distributed AI systems** and **cloud–edge–fog computing**, with an emphasis on **reliable, efficient orchestration** under real-world constraints (latency, bandwidth, energy, and privacy).

My work spans **task allocation across heterogeneous resources**, **multi-agent reinforcement learning (MARL)** for optimizing **service function chains (SFC)** and **virtual network functions (VNF)**, and **5G network slicing** using dynamic containerization and adaptive load balancing. I also develop **privacy-preserving federated learning** workflows, **scalable edge inference**, and **confidential computing** environments using hardware enclaves, prioritizing **reproducible and maintainable** research software.

## Research Interests
- Deep learning and federated learning  
- Multi-agent reinforcement learning for adaptive decision-making and large-scale optimization  
- Edge intelligence and distributed AI for real-time, resource-aware computing  
- Integrated edge–cloud–fog architectures for scalable, low-latency data processing  
- AI-driven autonomous network management and service orchestration  

## Selected Projects
- **<Project 1>** — <one-line value + outcome>  
  Repo: <link> · Demo/Docs: <link>

- **<Project 2>** — <one-line value + outcome>  
  Repo: <link> · Paper/Preprint: <link>

- **<Project 3>** — <one-line value + outcome>  
  Repo: <link> · Artifacts/Results: <link>

## Publications
- <Year> — **<Paper Title>**, <Venue> (PDF | Code)  
- <Year> — **<Paper Title>**, <Venue> (PDF | Code)  
Full list: <Google Scholar link>

## Awards & Leadership
- **Best Paper Award**, IEEE AIxMHC — <Year>
- **<Leadership Role>**, CCU Indian Community — <Year–Year>

## Skills (Selected)
- **Languages:** Python, Go, C/C++, Bash
- **AI/ML:** Deep Learning, MARL, Federated Learning, Compression, Multi-objective Optimization
- **ML Stack:** PyTorch, TensorFlow, scikit-learn, NumPy, pandas, OpenCV
- **Serving:** Triton Inference Server, FastAPI
- **Systems/DevOps:** Docker, Kubernetes, Helm, GitHub Actions/Jenkins
- **Cloud/Observability:** AWS/GCP/Azure, Prometheus, Grafana
- **Data & Tools:** PostgreSQL/MySQL/SQLite, Linux, Jupyter


---
